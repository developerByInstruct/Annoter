import google.generativeai as genai
from .base_provider import ModelProvider
from typing import Dict, Any, AsyncGenerator, Union
import google.generativeai as genai
from PIL import Image
import io
import base64

class GeminiProvider(ModelProvider):
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        
    async def generate(
        self, 
        prompt: Union[str, Dict[str, Any]], 
        model_id: str, 
        **kwargs
    ) -> Union[Dict[str, Any], AsyncGenerator[str, None]]:
        try:
            model = genai.GenerativeModel(model_id)
            stream = kwargs.pop('stream', False)
            
            if stream:
                return self._stream_response(model, prompt, **kwargs)
            
            # Rest of the existing non-streaming code...
            
        except Exception as e:
            print(f"Error in Gemini generation: {e}")
            return {"error": str(e), "text": "Error generating response with Gemini"}
            
    async def _stream_response(
        self, 
        model,
        prompt: Union[str, Dict[str, Any]], 
        **kwargs
    ) -> AsyncGenerator[str, None]:
        try:
            # Handle multimodal input
            if isinstance(prompt, dict) and "images" in prompt:
                processed_images = []
                for img_data in prompt["images"]:
                    if isinstance(img_data, str):
                        img_bytes = base64.b64decode(img_data)
                        img = Image.open(io.BytesIO(img_bytes))
                        processed_images.append(img)
                
                multimodal_input = [prompt["text"]] + processed_images
                response = model.generate_content(
                    multimodal_input,
                    stream=True,
                    **kwargs
                )
            else:
                response = model.generate_content(
                    prompt,
                    stream=True,
                    **kwargs
                )
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        except Exception as e:
            yield f"Error: {str(e)}"
    
    async def get_tokens_count(self, text: str) -> int:
        # Gemini doesn't provide token counting
        return len(text.split())  # Rough approximation
		
		
		
import PIL.Image
import os
import google.generativeai as genai

image_path_1 = "path/to/your/image1.jpeg"  # Replace with the actual path to your first image
image_path_2 = "path/to/your/image2.jpeg" # Replace with the actual path to your second image

sample_file_1 = PIL.Image.open(image_path_1)
sample_file_2 = PIL.Image.open(image_path_2)

#Choose a Gemini model.
model = genai.GenerativeModel(model_name="gemini-1.5-pro")

prompt = "Write an advertising jingle based on the items in both images."

response = model.generate_content([prompt, sample_file_1, sample_file_2])

print(response.text)